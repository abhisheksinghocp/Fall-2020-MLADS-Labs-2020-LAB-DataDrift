{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############Install below python libraries before running the functions\n",
    "dbutils.library.installPyPI(\"numpy\", version =\"1.16.4\")\n",
    "dbutils.library.installPyPI(\"pandas\", version =\"0.24.2\")\n",
    "dbutils.library.restartPython()\n",
    "dbutils.library.installPyPI(\"pyarrow\", version =\"0.17.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from datetime import date\n",
    "import pyarrow\n",
    "import os\n",
    "\n",
    "  \n",
    "def createFolder(directory):\n",
    "    try:\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "    except OSError:\n",
    "        print ('Error: Creating directory. ' +  directory)\n",
    "\n",
    "def scoring_file_parquet(dataframe,save_path,columns_excluded=None):\n",
    "  #**************V1 Created by Ankit Gupta***************************#\n",
    "  ####dataframe = Scoring Python data frame for which we need descriptive summary\n",
    "  ####save_path = save directory path for saving the file. Eg-'/dbfs/mnt/data/ModelOutput/Data_Drift/test/Scoring/'\n",
    "  ####columns_excluded = column to exclude from data drift(List) - This is optional. It is used to exlude ID colums like oppty ids, cut id etc which are not needed for data drift.Default value is None means no columns are excluded\n",
    "  if columns_excluded is not None:\n",
    "    dataframe_v1 = dataframe.drop(columns_excluded, axis=1).copy(deep=True)\n",
    "  else:\n",
    "    dataframe_v1=dataframe.copy(deep=True)\n",
    "#   dataframe.drop(columns_excluded, axis=1,inplace=True) ##############drop columns which are are needed for data dri\n",
    "  dataframe_v1['scoring_date'] = date.today()\n",
    "  dataframe_v1['scoring_date'] = pd.to_datetime(dataframe_v1['scoring_date'], infer_datetime_format=True)\n",
    "  #createFolder(save_path + datetime.today().strftime('%Y-%m-%d'))\n",
    "  model_save_path = save_path + datetime.today().strftime('%Y-%m-%d') +'.gzip'\n",
    "  dataframe_v1.to_parquet(model_save_path,compression='gzip',engine='pyarrow')\n",
    "  return \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pass the model training path as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####Sample Ttraing\n",
    "scoring_file_parquet(df,'<Training path>') # Pass the model scoring path as input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
